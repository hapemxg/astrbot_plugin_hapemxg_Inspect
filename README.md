# AstrBot LLM 回复审查插件 (Reviewer Plugin)

本插件为 AstrBot 提供了一个强大、高度可配置的 LLM (大语言模型) 回复内容审查框架。它像一个智能的“内容审核员”，在 AI 的回复发送给用户之前进行多层审查，确保内容的合规性与安全性。

当检测到不合规内容时，它不会简单地拦截，而是会智能地生成指导意见，让主模型进行自我修正和重试，从而形成一个“生成-审查-反馈-修正”的自动化闭环。

# 目录
- [插件优点](#插件优点)
- [潜在缺点](#潜在缺点)
- [使用方法](#使用方法)
- [配置选项详解](#配置选项详解)
- [支持](#支持)

## 插件优点

1.  **自动化安全屏障**：为你的聊天机器人提供 7x24 小时的自动化内容安全监控，有效拦截政治敏感、色情低俗、言语辱骂等不当言论，防止因 AI 回复不当导致封号等风险。
2.  **智能修正闭环**：本插件的核心优势在于其“审查-反馈-修正”机制。它不是简单地丢弃不合格的回复，而是能分析失败原因，并自动“指导”主模型如何修正，大大提高了最终回复的可用性和合规性。
3.  **高度可配置**：从审查开关到重试次数，从黑白名单规则到每一个审查维度的具体标准，几乎所有行为都可以通过 AstrBot 的网页管理界面进行详细配置，无需修改任何代码。
4.  **高效混合审查**：结合了基于正则表达式的“快速审查”和基于审查模型的“深度审查”。快速审查能以极低的成本高效过滤掉明确的违规内容，而深度审查则能更精准地理解语义和上下文，两者结合，兼顾了效率与准确性。
5.  **上下文感知能力**：在进行深度审查时，插件会参考最近的几轮对话历史，使得判断更加精准，能有效识别在特定语境下才显得不妥的内容。

## 潜在缺点

1.  **额外的 Token 消耗**：启用【深度审查】功能需要指定一个审查模型。这意味着每一次用户对话，除了主模型的消耗外，还会产生审查模型的调用开销。如果触发了重试机制，主模型也需要被再次调用。这会增加总体的 Token 消耗成本。
2.  **回复时间延长**：由于插件在 LLM 生成回复后增加了一道或多道审查与重试的环节，用户的最终接收到回复的时间会相应延长。延迟时间取决于审查模型的响应速度和重试次数。
3.  **配置有一定复杂性**：插件提供了极为丰富的配置选项，虽然带来了高度的灵活性，但也意味着需要用户花一些时间来理解每个选项的含义，以便根据自己的需求进行最佳配置。

## 使用方法

1.  **安装插件**：通过 AstrBot 的插件市场或手动将插件文件夹放入 `data/plugins` 目录来安装本插件。
2.  **进入配置页面**：启动 AstrBot，在 WebUI 的“插件市场”中找到本插件，点击“管理”进入配置页面。
3.  **核心配置（最重要的一步）**：
    *   找到 **`reviewer_provider_id` (用于内容审查的LLM提供商ID)** 这个配置项。
    *   你需要去 AstrBot 的“LLM 提供商”设置页面，**复制一个小模型的提供商 ID** (例如一个速度快、成本低的模型)，然后粘贴到这里。
    *   **注意：若此项留空，插件的【深度审查】核心功能将无法启用！**
4.  **启用插件**：将顶部的 **`enabled` (是否启用审查插件)** 开关打开。
5.  **按需调整**：根据下方的“配置选项详解”，按你的具体需求调整其他参数。
6.  **保存配置**：点击页面底部的“保存”按钮，插件即刻生效。

## 配置选项详解

下面是插件所有配置选项的详细说明，你可以根据这些说明来定制插件的行为。

### 全局设置
*   `enabled`: **插件总开关**。关闭后，插件将不执行任何操作。
*   `enable_console_logging`: **日志开关**。建议在初次配置和调试时开启。开启后，每一次审查的详细过程（包括命中规则、重试原因等）都会在 AstrBot 的后台控制台打印出来，便于你了解插件的运行情况。
*   `reviewer_provider_id`: **审查模型ID**。插件的灵魂。用于【深度审查】的模型ID，必须填写才能启用深度审查。
*   `deep_review_context_depth`: **上下文深度**。在进行深度审查时，插件会向前追溯多少轮已通过的对话作为参考。值越大，判断越准，但发送给审查模型的 Token 也越多。

### 重试与循环审查配置
*   `max_retries`: **最大重试次数**。当首次生成的内容未通过审查时，允许插件最多再尝试几次。例如，设置为 `3`，则总共最多会生成 4 次内容（1次初稿 + 3次重试）。
*   `send_failure_message_on_max_retries`: **重试失败后发送提示**。开启后，如果重试了 `max_retries` 次后仍然失败，会给用户发送一条友好的失败提示（内容可在下方 `user_facing_messages` 中配置）。
*   `strict_review_mode`: **严格审查模式**。强烈建议开启。开启后，如果审查模型调用失败或返回了无法解析的格式，插件会直接拦截消息。关闭则会放行，存在一定风险。

### 【快速审查】基于正则表达式的黑白名单配置
*   `enable_fast_review`: **启用快速审查**。在调用昂贵的审查模型前，先通过高效的正则表达式进行第一轮过滤。
*   `whitelist_regex`: **白名单**。定义回复**必须满足**的格式或内容。例如，你可以要求回复必须以句号结尾 `[。！？~]$`。
*   `whitelist_prompts`: **白名单驳回提示**。当不满足上方某条白名单规则时，用来指导模型重试的提示。规则名必须与上方一一对应。
*   `blacklist_regex`: **黑名单**。定义**绝不能出现**的词语或模式。只要命中任意一条，回复就会被立刻驳回。默认配置已包含“禁止讨论政治人物”和“禁止暴露AI身份”的示例。
*   `blacklist_prompts`: **黑名单驳回提示**。当命中上方某条黑名单规则时，用来指导模型重试的提示。规则名同样需要对应。你可以在提示词中使用 `{trigger_word}` 占位符，它会被自动替换为触发规则的具体词语。

### 【深度审查】审查级别与标准配置
这里定义了审查模型的工作细则。
*   `reviewer_system_prompt`: **审查模型的“总指令”**。这是一个模板，定义了审查员的核心任务和输出格式。通常不需要修改。
*   `enable_political`, `enable_pornographic`, `enable_verbal_abuse`, `enable_custom_rule`: **各审查维度的开关**。你可以根据需要开启或关闭对“政治敏感”、“色情低俗”、“言语辱骂”和“自定义规则”的审查。
*   `political_rule_prompt`, `pornographic_rule_prompt`, `verbal_abuse_rule_prompt`, `custom_rule_prompt`: **各审查维度的具体指导意见**。这里定义了每个维度的审查标准。你可以修改这些文本，让审查模型的判断标准更符合你的要求。例如，在自定义规则中加入“禁止泄露API密钥”等。

### 重试指令与用户提示配置
*   `retry_system_prompt`: **重试专用系统提示词**。如果填写，在重试环节，主模型的系统提示词将被**完全替换**为这里的内容。留空则沿用原始的系统提示词。
*   `retry_instruction_prompt`: **重试指导模板**。这是指导主模型修正回复的核心模板。其中的 `{review_comment}` 会被下方 `retry_guidance` 中生成的内容动态填充。
*   `retry_guidance`: **模块化重试指导**。你可以为每个审查维度（政治、色情等）定制更有针对性的重试指令。当某个维度的审查失败时，这里对应的模板就会被用来生成指导意见。`{reason}` 会被替换为审查员给出的具体原因。
*   `user_facing_messages`: **面向用户的提示语**。
    *   `final_failure`: 所有重试都失败后，发送给用户的最终消息。
    *   `internal_error`: 当插件自身发生错误（如无法调用审查模型）时，发送给用户的消息。